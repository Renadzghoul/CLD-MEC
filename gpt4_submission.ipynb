{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CLD-MEC**\n",
    "Clinical Linguistics Detection-Medical Error Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Any, Dict, Type\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"gpt4\": \"gpt-4-0125-preview\", \"gpt3\": \"gpt-3.5-turbo-0125\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_openai_tool(pydantic_class: Type[BaseModel]) -> Dict[str, Any]:\n",
    "    \"\"\"Convert pydantic class to OpenAI tool.\"\"\"\n",
    "    schema = pydantic_class.schema()\n",
    "    function = {\n",
    "        \"name\": schema[\"title\"],\n",
    "        \"description\": schema[\"description\"],\n",
    "        \"parameters\": pydantic_class.schema(),\n",
    "    }\n",
    "    return {\"type\": \"function\", \"function\": function}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessedNote(BaseModel):\n",
    "    \"\"\"Preprocess a clinical note by deleting the sentence that shows the cause and diagnosis.\"\"\"\n",
    "    label: int = Field(..., description=\"The label of the note. Binary flag of zero (note was not preprocessed) or one (note was preprocessed).\")\n",
    "    deleted_sentence: str = Field(\n",
    "        ..., description=\"The sentence that was deleted from the note. Could be an empty string if no sentence was deleted.\")\n",
    "    full_final_note: str = Field(...,\n",
    "                                 description=\"The final note after preprocessing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_note(clinical_note: str) -> str:\n",
    "    tools = [to_openai_tool(PreProcessedNote)]\n",
    "    response = client.chat.completions.create(\n",
    "        model=models[\"gpt4\"],  # change this for the prompt\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                I will give you a clinical note, you have to delete the shotest sentence that shows the cause or diagnosis, following to these conditions:\n",
    "                1) If the clinical note mentions any of clincal management actions (treatment, clinical care plan, or any intervention,....ect) related to ( management of past medical history, management history of present illness, diagnosis), then do not delete anything. Give this label 0.\n",
    "                2) Else, then delete the sentence that shows the cause and diagnosis. Give this label 1\n",
    "                3) Print the assigned labels 1 or 0.\n",
    "                4) Print the deleted part if applicable.\n",
    "                5) Print the full final note.\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": clinical_note,\n",
    "            },\n",
    "        ],\n",
    "        seed=42,\n",
    "        tools=tools,\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    outputs = []\n",
    "    for tool_call in tool_calls:\n",
    "        function_call = tool_call.function\n",
    "        # validations to get passed mypy\n",
    "        assert function_call is not None\n",
    "        assert function_call.name is not None\n",
    "        assert function_call.arguments is not None\n",
    "\n",
    "        name = function_call.name\n",
    "        arguments_str = function_call.arguments\n",
    "\n",
    "        if isinstance(function_call.arguments, dict):\n",
    "            output = PreProcessedNote.model_validate(function_call.arguments)\n",
    "        else:\n",
    "            output = PreProcessedNote.model_validate_json(\n",
    "                function_call.arguments)\n",
    "\n",
    "        outputs.append(output.model_dump_json())\n",
    "        return outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cot(preprocessed_note: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=models[\"gpt4\"],  # change this for the prompt\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                1)Based on Evidance-Based Medicine, use step-by-step deduction to create a differential diagnosis and then use step by step deduction to identify both of the most likly causing (Pathogen {name of the bacteria, worm, virus, fungi,....etc.}, poison,.... etc) and diagnosis separately. The answer should also be definitive to one cause and one diagnosis Without requiring any further clinical investigating action.\n",
    "                2) Then, step by step, deduce the most correct (treatment, clinical care plan, clinical management, intervention. )\n",
    "                You are designed to output JSON.\n",
    "                The JSON should be structured like this:\n",
    "                {\n",
    "                \"Differential Diagnosis Step by Step\": {\n",
    "                    \"Step 1\": ...,\n",
    "                    \"Step 2\": ...,\n",
    "                    \"Step N\": ...\n",
    "                    },\n",
    "                \"Differential Diagnosis\": { \n",
    "                    \"Most Likely Cause\": ...,\n",
    "                    \"Explanation\": ...\n",
    "                    },\n",
    "                \"Treatment Step by Step\": {\n",
    "                    \"Step 1\": ...,\n",
    "                    \"Step 2\": ...,\n",
    "                    \"Step N\": ...\n",
    "                    },\n",
    "                \"Definitive Diagnosis\": ...,\n",
    "                \"Treatment\": {\n",
    "                    \"Definitive Treatment\": ...\n",
    "                    }\n",
    "                }\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": preprocessed_note,\n",
    "            },\n",
    "        ],\n",
    "        seed=42,\n",
    "    )\n",
    "    return str(json.loads(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword(cot: str, clinical_note: str) -> dict:\n",
    "    # step 1 01\n",
    "    response = client.chat.completions.create(\n",
    "        model=models[\"gpt4\"],  # change this for the prompt\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"\n",
    "                1) Use this interpretable clinical reasoning rationale you have produced for this clinial note: \n",
    "                {cot}\n",
    "                2) Based on the interpretable clinical reasoning rationale, If the clinical note mentions a diagnosis or a medical condition that is based on a clinal presentation or findings that are not directly connected to each other in most common clinical contexts, then there should be a medical error in the diagnosis.\n",
    "                3) Delete the diagnosis or a medical condition related keyword from the clinical note.\n",
    "                4) Print the deleted keyword if applicable.\n",
    "                5) Print the full final note, where the deleted keyword should be masked with this label -> \"0\"\n",
    "                You are designed to output JSON.\n",
    "                It has to be structured like this:\n",
    "                {{\n",
    "                \"DeletedKeyword\": ...,\n",
    "                \"FullFinalNote\": ...\n",
    "                }}\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": clinical_note},\n",
    "        ],\n",
    "        seed=42,\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)[\"FullFinalNote\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cot_no_keyword(removed_keyword: str) -> str:\n",
    "    # step 1 02\n",
    "    # step 1 02\n",
    "    response = client.chat.completions.create(\n",
    "        model=models[\"gpt4\"],  # change this for the prompt\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                1)Based on Evidance-Based Medicine, use step-by-step deduction to create a differential diagnosis and then use step by step deduction to identify both of the most likly causing (Pathogen {name of the bacteria, worm, virus, fungi,....etc.}, poison,.... etc) and diagnosis separately. The answer should also be definitive to one cause and one diagnosis Without requiring any further clinical investigating action.\n",
    "                2) Then, step by step, deduce the most correct (treatment, clinical care plan, clinical management, intervention. )\n",
    "                You are designed to output JSON.\n",
    "                The JSON should be structured like this:\n",
    "                {\n",
    "                \"Differential Diagnosis Step by Step\": {\n",
    "                    \"Step 1\": ...,\n",
    "                    \"Step 2\": ...,\n",
    "                    \"Step N\": ...\n",
    "                    },\n",
    "                \"Differential Diagnosis\": { \n",
    "                    \"Most Likely Cause\": ...,\n",
    "                    \"Explanation\": ...\n",
    "                    },\n",
    "                \"Treatment Step by Step\": {\n",
    "                    \"Step 1\": ...,\n",
    "                    \"Step 2\": ...,\n",
    "                    \"Step N\": ...\n",
    "                    },\n",
    "                \"Definitive Diagnosis\": ...,\n",
    "                \"Treatment\": {\n",
    "                    \"Definitive Treatment\": ...\n",
    "                    }\n",
    "                }\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": removed_keyword,\n",
    "            },\n",
    "        ],\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    return str(json.loads(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_cot(cot_round_two: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=models[\"gpt4\"],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"\n",
    "                you have to verify your interpretable clinical reasoning rationale of diagnosis you have produced of its related clinial note. the verification should be by genirating questions that target and retive information from the most apprpriate clinical practice guidelines.\n",
    "                -make the query adress the name of the guidline you want to retrive that response from.\n",
    "                -if you want ro check fro the diagnosis clinical findings, make the query adress the related clinical findigs you want to check for the diagnosis.\n",
    "                -make the directed query adress the most liky correct (cause, diagnosis).\n",
    "                -make the direced query adress the recommendations part of the guidline related to (diagnosis, clinical management, treatment, drug of choice)\n",
    "                -search from the directed guidlines.\n",
    "                -returt the information you gained.\n",
    "                -compare your interpretable clinical reasoning rationale with the retrived information from the guidline, if there is discrepency, show it.\n",
    "                -if there is a major discrepency, take the retrived information as ground truth and print out the final COT after being revised.\n",
    "                You are designed to output JSON.\n",
    "                It has to be structured like this:\n",
    "                {{\n",
    "                \"VerificationQueries\": {\n",
    "                    \"Query 1\": ...,\n",
    "                    \"Query 2\": ...,\n",
    "                    \"Query 3\": ...,\n",
    "                    \"Query N\": ...\n",
    "                },\n",
    "                \"RetrievedInformation\": {\n",
    "                    \"Response 1\": ...,\n",
    "                    \"Response 2\": ...,\n",
    "                    \"Response 3\": ...,\n",
    "                    \"Response N\": ...\n",
    "                },\n",
    "                \"Comparison\": {\n",
    "                    \"Clinical Findings\": ...,\n",
    "                    \"Causes\": ...,\n",
    "                    \"Treatment\": ...\n",
    "                },\n",
    "                \"Discrepancy\": ... (could be nullable),\n",
    "                \"FinalCOT\": {\n",
    "                    \"Differential Diagnosis Process\": {\n",
    "                    \"Step 1\": ...,\n",
    "                    \"Step 2\": ...,\n",
    "                    \"Step 3\": ...,\n",
    "                    \"Step N\": ...\n",
    "                    },\n",
    "                    \"Definitive Cause\": {\n",
    "                    \"Most Likely Pathogen/Cause\": ...\n",
    "                    },\n",
    "                    \"Definitive Diagnosis\": ...,\n",
    "                    \"Treatment Plan\": {\n",
    "                    \"Step 1\": ...,\n",
    "                    \"Step 2\": ...,\n",
    "                    \"Step 3\": ...,\n",
    "                    \"Step 4\": ...,\n",
    "                    \"Step N\": ...\n",
    "                    }\n",
    "                }\n",
    "                }}\n",
    "                You are designed to output JSON.\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": cot_round_two,\n",
    "            },\n",
    "        ],\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    return str(json.loads(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalRevision(BaseModel):\n",
    "    \"\"\"Revise and correct a clinical note based on the clinical reasoning rationale.\"\"\"\n",
    "\n",
    "    error_flag: int = Field(\n",
    "        ...,\n",
    "        description=\"The error flag of the note. Binary flag of zero (note was not revised) or one (note was revised).\",\n",
    "    )\n",
    "    error_location: int = Field(\n",
    "        ...,\n",
    "        description=\"The location of the error in the note. Could be an empty string if no error was found. The note is split into sentences with an index for each, return that index.\",\n",
    "    )\n",
    "    sentence_correction: str = Field(\n",
    "        ...,\n",
    "        description=\"The corrected sentence based on the clinical reasoning rationale.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise_and_correct(verified_cot: str, clinical_note: str) -> str | dict:\n",
    "    tools = [to_openai_tool(FinalRevision)]\n",
    "    response = client.chat.completions.create(\n",
    "        model=models[\"gpt4\"],  # change this for the prompt\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"\n",
    "                1) Use this interpretable clinical reasoning rationale you have produce as a ground truth\n",
    "                {verified_cot}\n",
    "                2) compare if the clinical note match the ground truth to tell if the clinical note has a medical error in (diagnosis (pathogen, poison, disease), clinical manageent (treatment, clinical care plan, intervention (oreder certaint lab test, tranfer, certain image by name, procesure).).\n",
    "                3) Identify any dicrepency between the ground truth and the clinical note.\n",
    "                4) then if there is any thing in the clinical note related to either diagnosis or cause  that is not available (referenced) in the groung truth reference, then label it as medical error. and skip the steps related to clinical management.\n",
    "                5) then else if there is any thing in the clinical note related to clinial managemnt after diagnosis is not available (referenced) in the groung truth reference specifically in (clinical management related sectons), then label it as medical error.  and skip the steps related to the diagnosis or cause.\n",
    "                If there is a medical error, identify it's type (diagnosis, cause, or clinical management) and print it, identify the exact related shotest part and print it, and correct it with the shortest possiple correction. do not change the format of the correced part only correct the relaed keyword.\n",
    "                Then if the error type is erelated to clincal management related errors, the corrected sentance should be definative to the exact needed medication, procesure, image,..... ect. not general. not as a recommendation. correct the note directly with the most corret propable needed audit.\n",
    "                If the error type related to diagnosis, cause, or clinical management consider this error correction to be edited on the final corrected note. the priority to add the correction of diagnosis and cause first to be considered. consider one correction only, depend on the context.\n",
    "                finally print out the corrected final note.\n",
    "\n",
    "                The clinical note you have to correct is split into sentences with an index for each.\n",
    "                The correction you return includes the error flag, the error location, and the sentence correction.\n",
    "\n",
    "                \"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": clinical_note,\n",
    "            },\n",
    "        ],\n",
    "        seed=42,\n",
    "        tools=tools,\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    if tool_calls:\n",
    "        outputs = []\n",
    "        for tool_call in tool_calls:\n",
    "            function_call = tool_call.function\n",
    "            # validations to get passed mypy\n",
    "            assert function_call is not None\n",
    "            assert function_call.name is not None\n",
    "            assert function_call.arguments is not None\n",
    "\n",
    "            name = function_call.name\n",
    "            arguments_str = function_call.arguments\n",
    "\n",
    "            if isinstance(function_call.arguments, dict):\n",
    "                output = FinalRevision.model_validate(function_call.arguments)\n",
    "            else:\n",
    "                output = FinalRevision.model_validate_json(\n",
    "                    function_call.arguments)\n",
    "\n",
    "            outputs.append(output.model_dump_json())\n",
    "            return outputs[0]\n",
    "    else:\n",
    "        return {\"error_flag\": 0, \"error_location\": -1, \"sentence_correction\": \"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_note(clinical_note: str, clinical_note_sentences: str) -> str | dict:\n",
    "    preprocessed_note = json.loads(preprocess_note(clinical_note))[\n",
    "        \"full_final_note\"]\n",
    "    cot_round_1 = cot(preprocessed_note)\n",
    "    removed_keyword = keyword(cot_round_1, clinical_note)\n",
    "    cot_round_two = cot_no_keyword(removed_keyword)\n",
    "    verified_cot = verify_cot(cot_round_two)\n",
    "    final_note = revise_and_correct(verified_cot, clinical_note_sentences)\n",
    "    return final_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\n",
    "    \"March-26-2024-MEDIQA-CORR-Official-Test-Set.csv\", encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = [test.iloc[i, :].values.tolist() for i in range(0, 100)]\n",
    "batch_2 = [test.iloc[i, :].values.tolist() for i in range(100, 200)]\n",
    "batch_3 = [test.iloc[i, :].values.tolist() for i in range(200, 300)]\n",
    "batch_4 = [test.iloc[i, :].values.tolist() for i in range(300, 400)]\n",
    "batch_5 = [test.iloc[i, :].values.tolist() for i in range(400, 500)]\n",
    "batch_6 = [test.iloc[i, :].values.tolist() for i in range(500, 600)]\n",
    "batch_7 = [test.iloc[i, :].values.tolist() for i in range(600, 700)]\n",
    "batch_8 = [test.iloc[i, :].values.tolist() for i in range(700, 800)]\n",
    "batch_9 = [test.iloc[i, :].values.tolist() for i in range(800, 900)]\n",
    "batch_10 = [test.iloc[i, :].values.tolist() for i in range(900, 925)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "925"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(batch_1) + len(batch_2) + len(batch_3) + len(batch_4) + len(batch_5) + \\\n",
    "    len(batch_6) + len(batch_7) + len(batch_8) + len(batch_9) + len(batch_10) == len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch) -> None:\n",
    "    for item in batch:\n",
    "        try:\n",
    "            result = correct_note(item[1], item[2])\n",
    "            with open(f\"corrected_notes/{item[0]}.txt\", \"w\") as f:\n",
    "                f.write(f\"{result}\\n\")\n",
    "        except Exception as e:\n",
    "            failed.append(item[0])\n",
    "            print(f\"{e} | {item[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    batches = [batch_1, batch_2, batch_3, batch_4, batch_5,\n",
    "               batch_6, batch_7, batch_8, batch_9, batch_10]\n",
    "    futures = {executor.submit(process_batch, batch)               : i for i, batch in enumerate(batches, start=1)}\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        batch_num = futures[future]\n",
    "        try:\n",
    "            future.result()\n",
    "        except Exception as exc:\n",
    "            logging.error(f'Batch_{batch_num} generated an exception: {exc}')\n",
    "        else:\n",
    "            logging.info(f'Batch_{batch_num} is complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_notes = glob(\"corrected_notes/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(corrected_notes) == len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in corrected_notes:\n",
    "    id = path.split(\"/\")[-1].split(\".\")[0]\n",
    "    with open(path) as f:\n",
    "        notes[id] = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for note in notes:\n",
    "    if notes[note][\"error_flag\"] == 0:\n",
    "        notes[note][\"error_location\"] = -1\n",
    "        notes[note][\"sentence_correction\"] = \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prediction.txt\", \"w\") as f:\n",
    "    for note in notes:\n",
    "        f.write(\n",
    "            f\"{note} {notes[note]['error_flag']} {notes[note]['error_location']} \\\"{notes[note]['sentence_correction']}\\\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
